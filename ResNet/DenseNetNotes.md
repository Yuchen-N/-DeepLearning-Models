# DenseNet
## DenseNet 与 ResNet 的对比

相比于 ResNet 的“跳跃连接”，DenseNet 采用了更加密集的连接方式：每一层的输出都会连接到后面所有的层。这意味着网络中的每一层都能直接接收到前面所有层的特征信息。公式上表示为：

\[
H_l = [x_0, x_1, ..., x_{l-1}, x_l]
\]

其中 \( H_l \) 是第 \( l \) 层的输出，而输入是所有前面层的输出的拼接。

### DenseNet 的核心设计

- **每一层的输入是所有前面层的输出的拼接**，而不仅仅是前一层的输出。DenseNet 的每一层都能够看到所有前面层的特征，形成了一个“全连接”的特征图路径。
- **特征复用**：每一层的输出都会被后续层多次使用，而不是像 ResNet 一样只被下一层直接使用。

### DenseNet 是 ResNet 的“极端版本”

可以认为 DenseNet 是 ResNet 的“极端版本”，因为它极大地增强了层与层之间的连接：

- **ResNet**：每一层只与下一层连接，并通过残差块跳跃连接部分信息。
- **DenseNet**：每一层与所有后面的层连接，形成了更加密集的连接方式，让每一层都能复用所有前面层的特征。

这让 DenseNet 在特征传递和梯度传递方面更加高效和紧密。正是因为这种连接的密集性，使得网络在梯度传递、特征复用、模型紧凑性上更为优越。
